{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Tutoriel PyRaTe Logiciel con\u00e7u pour les projets de t\u00e9l\u00e9d\u00e9tection des \u00e9tudiants de L3 de l'Universit\u00e9 de Versailles Saint-Quentin (UVSQ) Introduction PyRaTe est une biblioth\u00e8que Python con\u00e7ue pour vous aider lors de vos projets de \"t\u00e9l\u00e9d\u00e9tection\". Il s'agit un package de fonctions vous permettant d'entrainer un classifieur \u00e0 identifier les pixels dans une image satellite \"raster\" multi-bande : un probl\u00e8me classique en t\u00e9l\u00e9d\u00e9tection. Elle contient des fonctions pour : L' importation des diff\u00e9rentes bandes d'une image satellite au format GeoTIFF . Un affichage RGB g\u00e9or\u00e9f\u00e9renc\u00e9 \u00e0 partir de 3 bandes d'une image satellite. Lab\u00e9liser des pixels d'une image donn\u00e9e, pour constituer une base de donn\u00e9es d'entrainement sous la forme d'un DataFrame Pandas. Afficher la distribution des pixels d'une base de donn\u00e9es (par bande et par label). Entrainer un classifieur \u00e0 identifier les pixels dans une image satellite. Tester les performances d'un classifieur sur des pixels autres que ceux des donn\u00e9es d'entrainement. Afficher les labels pr\u00e9dits pour les pixels d'une image, avec g\u00e9or\u00e9f\u00e9rencement. Vous trouverez sur ce site web un tutoriel pour prendre en main PyRaTe , sur un exemple d'image satellite \"raster\" multi-bande. Installation T\u00e9l\u00e9chargez la derni\u00e8re version de PyRaTe sa page GitHub, dans l'onglet \"Releases\" : Lien vers PyRaTe Enregistrez le dossier t\u00e9l\u00e9charg\u00e9 (et d\u00e9zipp\u00e9) sur votre ordinateur. Pour installer PyRaTe , r\u00e9cup\u00e9rez le chemin o\u00f9 vous l'avez enregistr\u00e9e sur votre ordinateur \"path/PyRaTe\" et utilisez la commande Python : pip install path/PyRaTe Une fois PyRaTe install\u00e9e, vous pourrez l'importer sous Python avec la commande : import PyRaTe C'est bon, vous pouvez utiliser PyRaTe ! Credits \u00a9 Nicolas OUDART LATMOS/IPSL, UVSQ Universit\u00e9 Paris-Saclay, Guyancourt, France","title":"Introduction"},{"location":"#tutoriel-pyrate","text":"Logiciel con\u00e7u pour les projets de t\u00e9l\u00e9d\u00e9tection des \u00e9tudiants de L3 de l'Universit\u00e9 de Versailles Saint-Quentin (UVSQ)","title":"Tutoriel PyRaTe"},{"location":"#introduction","text":"PyRaTe est une biblioth\u00e8que Python con\u00e7ue pour vous aider lors de vos projets de \"t\u00e9l\u00e9d\u00e9tection\". Il s'agit un package de fonctions vous permettant d'entrainer un classifieur \u00e0 identifier les pixels dans une image satellite \"raster\" multi-bande : un probl\u00e8me classique en t\u00e9l\u00e9d\u00e9tection. Elle contient des fonctions pour : L' importation des diff\u00e9rentes bandes d'une image satellite au format GeoTIFF . Un affichage RGB g\u00e9or\u00e9f\u00e9renc\u00e9 \u00e0 partir de 3 bandes d'une image satellite. Lab\u00e9liser des pixels d'une image donn\u00e9e, pour constituer une base de donn\u00e9es d'entrainement sous la forme d'un DataFrame Pandas. Afficher la distribution des pixels d'une base de donn\u00e9es (par bande et par label). Entrainer un classifieur \u00e0 identifier les pixels dans une image satellite. Tester les performances d'un classifieur sur des pixels autres que ceux des donn\u00e9es d'entrainement. Afficher les labels pr\u00e9dits pour les pixels d'une image, avec g\u00e9or\u00e9f\u00e9rencement. Vous trouverez sur ce site web un tutoriel pour prendre en main PyRaTe , sur un exemple d'image satellite \"raster\" multi-bande.","title":"Introduction"},{"location":"#installation","text":"T\u00e9l\u00e9chargez la derni\u00e8re version de PyRaTe sa page GitHub, dans l'onglet \"Releases\" : Lien vers PyRaTe Enregistrez le dossier t\u00e9l\u00e9charg\u00e9 (et d\u00e9zipp\u00e9) sur votre ordinateur. Pour installer PyRaTe , r\u00e9cup\u00e9rez le chemin o\u00f9 vous l'avez enregistr\u00e9e sur votre ordinateur \"path/PyRaTe\" et utilisez la commande Python : pip install path/PyRaTe Une fois PyRaTe install\u00e9e, vous pourrez l'importer sous Python avec la commande : import PyRaTe C'est bon, vous pouvez utiliser PyRaTe !","title":"Installation"},{"location":"#credits","text":"\u00a9 Nicolas OUDART LATMOS/IPSL, UVSQ Universit\u00e9 Paris-Saclay, Guyancourt, France","title":"Credits"},{"location":"entrainement/","text":"Entrainement d'un classifieur Maintenant que nous avons import\u00e9 notre image \"raster\", nous allons utiliser PyRaTe pour entrainer un classifieur \u00e0 pr\u00e9dire les labels associ\u00e9s aux pixels de l'image. Principe de la classification supervis\u00e9e Ce que nous nous appr\u00eatons \u00e0 faire ici est de la \" classification supervis\u00e9e \". En \"apprentissage automatique\" (ou \"Machine-Learning\" en anglais), on essaye d'enseigner \u00e0 un mod\u00e8le comment renvoyer les sorties attendues \u00e0 partir d'une s\u00e9lection d'entr\u00e9es. Suivant la nature de la sortie, on parlera de : R\u00e9gression si la sortie est quantitative et continue. Classification si la sortie est quantitative discr\u00e8te ou qualitative. Comme ici notre sortie est un \"label\" (ou \"\u00e9tiquette\") que nous voulons attribuer \u00e0 un pixel \u00e0 partir des valeurs qu'il contient dans les diff\u00e9rentes bandes, nous sommes clairement face \u00e0 un probl\u00e8me de \" classification \". L'expression \" supervis\u00e9e \" vient du fait que pour enseigner \u00e0 notre mod\u00e8le comment pr\u00e9dire les labels corrects pour les pixels de l'image, nous allons lui fournir des exemples de pixels d\u00e9j\u00e0 lab\u00e9lis\u00e9s pour qu'il puisse s' entrainer . Au cours de l'entrainement, le mod\u00e8le peut donc comparer ses pr\u00e9dictions aux labels attendus pour cet exemple, d'o\u00f9 le c\u00f4t\u00e9 \"supervis\u00e9\". Par opposition, ce que l'on appelle \"classification non-supervis\u00e9e\" serait ici le fait de s\u00e9parer les pixels en diff\u00e9rents groupes suivant les valeurs qu'ils contiennent dans les diff\u00e9rentes bandes, sans a priori sur l'identification du pixel. On parle aussi de \"clustering\". M\u00e9thode de la d\u00e9cision Bay\u00e9sienne Une des m\u00e9thodes de base pour la classification supervis\u00e9e est la \" d\u00e9cision Bay\u00e9sienne \" (ou \"Naive Bayes\" en anglais). Le principe est le suivant : essayer d'estimer la probabilit\u00e9 conditionnelle d'un pixel d'avoir un label sachant les valeurs qu'il contient. Le label ayant la plus grande probabilit\u00e9 conditionnelle est attribu\u00e9 \u00e0 ce pixel. Comme son nom l'indique, cette m\u00e9thode va d\u00e9terminer la probabilit\u00e9 conditionnelle de chaque classe en se basant sur la formule de Bayes . Un mod\u00e8le Gaussien est d'abord ajust\u00e9 \u00e0 la distribution des pixels au sein de chaque label dans les donn\u00e9es d'entrainement gr\u00e2ce \u00e0 l'algorithme du \"maximum de vraisemblance\" (ou \"maximum likelihood\" en anglais). Ce mod\u00e8le est ensuite utilis\u00e9 dans la formule de Bayes pour calculer les probabilit\u00e9s conditionnelles de n'importe quel pixel pour chaque classe. On peut tracer une fronti\u00e8re de d\u00e9cision entre les labels en tra\u00e7ant la ligne des valeurs de pixels pour lesquelles les probabilit\u00e9s conditionnelles entre 2 labels sont \u00e9gales. Voici une illustration de la m\u00e9thode pour un exemple simple avec un \"raster\" \u00e0 2 bandes, et 2 labels possibles pour les pixels : Pour plus d'informations sur la m\u00e9thode, cliquez sur ce lien : Cours sur la d\u00e9cision Bay\u00e9sienne . G\u00e9n\u00e9rer une base de donn\u00e9es d'entrainement Comme nous l'avons expliqu\u00e9 pr\u00e9c\u00e9demment, la classification supervis\u00e9e n\u00e9cessite une phase d' entrainement , o\u00f9 nous enseignons au mod\u00e8le comment pr\u00e9dire les bons labels \u00e0 partir d'une base de donn\u00e9es de pixels d\u00e9j\u00e0 lab\u00e9lis\u00e9s. Pour la d\u00e9cision Bay\u00e9sienne, ceci correspond \u00e0 la phase de d\u00e9termination du mod\u00e8le Gaussien de distribution des pixels au sein de chaque label. Nous devons donc constituer une base de donn\u00e9es de pixels, avec pour chacun un label associ\u00e9. Avec PyRaTe , vous devrez utiliser la commande suivante : df_training = PyRaTe.labelling(band_list,display_rgb=[3,2,1]) (Le param\u00e8tre display_rgb vous permet de choisir les couleurs de l'affichage que vous d\u00e9sirez). La fen\u00eatre suivante s'ouvre alors : Pour chaque label \u00e0 ajouter \u00e0 la base de donn\u00e9es d'entrainement : Entrez le label dans la zone de texte en bas de la fen\u00eatre. S\u00e9lectionnez avec le clic gauche de la souris des rectangles sur l'image correspondant \u00e0 ce label. Voici par exemple avec notre image Sentinel-2, la s\u00e9lection des labels \"forest\", \"field\", \"water\" et \"city\" : L'id\u00e9e n'est pas de s\u00e9lectionner tous les pixels de l'image correspondant \u00e0 un label donn\u00e9, mais d'\u00eatre le plus repr\u00e9sentatif possible de ce label. Quand vous avez termin\u00e9, cliquez sur \"Finish\". Un message s'affiche dans la console Python : Il contient le nombre de pixels s\u00e9lectionn\u00e9s pour chaque label. La variable df_training contient les donn\u00e9es d'entrainement sous la forme d'un DataFrame Pandas . Il s'agit d'une sorte de tableau, contenant une colonne pour chaque bande de fr\u00e9quence, et une colonne pour le label. Chaque ligne correspond \u00e0 un pixel s\u00e9lectionn\u00e9. Nous utiliserons ce DataFrame pour entrainer notre mod\u00e8le. Nota Bene Il est possible de sauvegarder votre base de donn\u00e9es d'entrainement sous la forme d'un fichier CSV avec la m\u00e9thode Pandas to_csv . Ce CSV pourra \u00eatre import\u00e9 plus tard sous la forme d'un DataFrame Pandas avec la m\u00e9thode read_csv . Vous pouvez \u00e9galement cr\u00e9er des DataFrame Pandas de donn\u00e9es d'entrainement pour diff\u00e9rentes images, et les fusionner en une seule base par la suite, avec la m\u00e9thode concat . Ne n\u00e9gligez surtout pas l'\u00e9tape de la constitution d'une base de donn\u00e9es d'entrainement : un classifieur entrain\u00e9 sur des donn\u00e9es de mauvaise qualit\u00e9 aura des performances mauvaises, Garbage In, Garbage Out . Pour qu'un mod\u00e8le soit performant, il lui faut des donn\u00e9es de qualit\u00e9 (correctement lab\u00e9lis\u00e9es, repr\u00e9sentatives) et en quantit\u00e9 (plusieurs milliers de pixels si possible). Dans l'id\u00e9al, il faut que les donn\u00e9es d'entrainement soient le plus repr\u00e9sentatives possibles des cas d'application de vos projets, en provenant potentiellement de plusieurs images diff\u00e9rentes. Etude statistique des donn\u00e9es Avant d'entrainer un classifieur, il est important de v\u00e9rifier la s\u00e9parabilit\u00e9 des diff\u00e9rents labels suivants les valeurs dans les diff\u00e9rentes bandes du \"raster\". Et avant d'entrainer un classifieur de type \"d\u00e9cision Bay\u00e9sienne\", il est important de v\u00e9rifier si l' hypoth\u00e8se Gaussienne des distributions a du sens. C'est pourquoi on veut en g\u00e9n\u00e9ral afficher des histogrammes de la r\u00e9partition des valeurs des pixels de notre base d'entrainement pour les diff\u00e9rents labels et pour les diff\u00e9rentes bandes. Ceci est possible avec PyRaTe , en utilisant la commande : PyRaTe.dataset_statistics(df_training) On obtient alors les 10 histogrammes suivants (un par bande) : Certaines bandes du \"raster\" ont-elles l'air plus pertinentes que d'autres pour s\u00e9parer nos diff\u00e9rents labels ? L'hypoth\u00e8se Gaussienne des distributions a-t-elle l'air raisonnable ? Dans le cadre de vos projets, il faudra vous poser ces questions. Nota Bene Si elle n'apporte pas grand chose, une bande peut \u00eatre retir\u00e9e du DataFrame avec la m\u00e9thode Pandas drop . Il faut n\u00e9anmoins avoir en t\u00eate qu'une seule bande est rarement suffisante pour s\u00e9parer 2 labels : il faut souvent utiliser la combinaison de plusieurs bandes. Entrainement Maintenant que nous avons v\u00e9rifi\u00e9 la qualit\u00e9 de notre base de donn\u00e9es d'entrainement, nous allons pouvoir l'utiliser pour entrainer notre mod\u00e8le. Voici la commande pour obtenir la \"pipeline\" de notre mod\u00e8le \u00e0 partir des donn\u00e9es d'entrainement (l'apprentissage peut prendre un peu de temps) : classifier_pipeline = PyRaTe.training(df_training) On parle ici de \"pipeline\" car il n'y a en r\u00e9alit\u00e9 pas que le classifieur. Les valeurs de pixels pour les diff\u00e9rentes bandes subissent une mise \u00e0 l'\u00e9chelle avant passage dans le classifieur. Un message apparait dans la console Python : Il s'agit de l' exactitude (\"accuracy\" en anglais) de notre mod\u00e8le sur les donn\u00e9es d'entrainement. Exactitude L'exactitude est un crit\u00e8re de performance classique pour un classifieur. Elle correspond au ratio entre le nombre pr\u00e9dictions correctes et le nombre total de pr\u00e9dictions. Ce crit\u00e8re r\u00e9sume bien les performances d'un classifieur tant que les labels ne sont pas trop d\u00e9s\u00e9quilibr\u00e9s au sein de la base de donn\u00e9es. Ce crit\u00e8re donne par d\u00e9finition des valeurs entre 0 et 1. Plus il est proche de 1, meilleur est le classifieur sur ces donn\u00e9es. L'entrainement s'est-il bien pass\u00e9 ici ? Pensez-vous qu'une exactitude \u00e9lev\u00e9e sur les donn\u00e9es d'entrainement est suffisante pour juger des performances du classifieur de mani\u00e8re g\u00e9n\u00e9rale ?","title":"Entrainement"},{"location":"entrainement/#entrainement-dun-classifieur","text":"Maintenant que nous avons import\u00e9 notre image \"raster\", nous allons utiliser PyRaTe pour entrainer un classifieur \u00e0 pr\u00e9dire les labels associ\u00e9s aux pixels de l'image.","title":"Entrainement d'un classifieur"},{"location":"entrainement/#principe-de-la-classification-supervisee","text":"Ce que nous nous appr\u00eatons \u00e0 faire ici est de la \" classification supervis\u00e9e \". En \"apprentissage automatique\" (ou \"Machine-Learning\" en anglais), on essaye d'enseigner \u00e0 un mod\u00e8le comment renvoyer les sorties attendues \u00e0 partir d'une s\u00e9lection d'entr\u00e9es. Suivant la nature de la sortie, on parlera de : R\u00e9gression si la sortie est quantitative et continue. Classification si la sortie est quantitative discr\u00e8te ou qualitative. Comme ici notre sortie est un \"label\" (ou \"\u00e9tiquette\") que nous voulons attribuer \u00e0 un pixel \u00e0 partir des valeurs qu'il contient dans les diff\u00e9rentes bandes, nous sommes clairement face \u00e0 un probl\u00e8me de \" classification \". L'expression \" supervis\u00e9e \" vient du fait que pour enseigner \u00e0 notre mod\u00e8le comment pr\u00e9dire les labels corrects pour les pixels de l'image, nous allons lui fournir des exemples de pixels d\u00e9j\u00e0 lab\u00e9lis\u00e9s pour qu'il puisse s' entrainer . Au cours de l'entrainement, le mod\u00e8le peut donc comparer ses pr\u00e9dictions aux labels attendus pour cet exemple, d'o\u00f9 le c\u00f4t\u00e9 \"supervis\u00e9\". Par opposition, ce que l'on appelle \"classification non-supervis\u00e9e\" serait ici le fait de s\u00e9parer les pixels en diff\u00e9rents groupes suivant les valeurs qu'ils contiennent dans les diff\u00e9rentes bandes, sans a priori sur l'identification du pixel. On parle aussi de \"clustering\".","title":"Principe de la classification supervis\u00e9e"},{"location":"entrainement/#methode-de-la-decision-bayesienne","text":"Une des m\u00e9thodes de base pour la classification supervis\u00e9e est la \" d\u00e9cision Bay\u00e9sienne \" (ou \"Naive Bayes\" en anglais). Le principe est le suivant : essayer d'estimer la probabilit\u00e9 conditionnelle d'un pixel d'avoir un label sachant les valeurs qu'il contient. Le label ayant la plus grande probabilit\u00e9 conditionnelle est attribu\u00e9 \u00e0 ce pixel. Comme son nom l'indique, cette m\u00e9thode va d\u00e9terminer la probabilit\u00e9 conditionnelle de chaque classe en se basant sur la formule de Bayes . Un mod\u00e8le Gaussien est d'abord ajust\u00e9 \u00e0 la distribution des pixels au sein de chaque label dans les donn\u00e9es d'entrainement gr\u00e2ce \u00e0 l'algorithme du \"maximum de vraisemblance\" (ou \"maximum likelihood\" en anglais). Ce mod\u00e8le est ensuite utilis\u00e9 dans la formule de Bayes pour calculer les probabilit\u00e9s conditionnelles de n'importe quel pixel pour chaque classe. On peut tracer une fronti\u00e8re de d\u00e9cision entre les labels en tra\u00e7ant la ligne des valeurs de pixels pour lesquelles les probabilit\u00e9s conditionnelles entre 2 labels sont \u00e9gales. Voici une illustration de la m\u00e9thode pour un exemple simple avec un \"raster\" \u00e0 2 bandes, et 2 labels possibles pour les pixels : Pour plus d'informations sur la m\u00e9thode, cliquez sur ce lien : Cours sur la d\u00e9cision Bay\u00e9sienne .","title":"M\u00e9thode de la d\u00e9cision Bay\u00e9sienne"},{"location":"entrainement/#generer-une-base-de-donnees-dentrainement","text":"Comme nous l'avons expliqu\u00e9 pr\u00e9c\u00e9demment, la classification supervis\u00e9e n\u00e9cessite une phase d' entrainement , o\u00f9 nous enseignons au mod\u00e8le comment pr\u00e9dire les bons labels \u00e0 partir d'une base de donn\u00e9es de pixels d\u00e9j\u00e0 lab\u00e9lis\u00e9s. Pour la d\u00e9cision Bay\u00e9sienne, ceci correspond \u00e0 la phase de d\u00e9termination du mod\u00e8le Gaussien de distribution des pixels au sein de chaque label. Nous devons donc constituer une base de donn\u00e9es de pixels, avec pour chacun un label associ\u00e9. Avec PyRaTe , vous devrez utiliser la commande suivante : df_training = PyRaTe.labelling(band_list,display_rgb=[3,2,1]) (Le param\u00e8tre display_rgb vous permet de choisir les couleurs de l'affichage que vous d\u00e9sirez). La fen\u00eatre suivante s'ouvre alors : Pour chaque label \u00e0 ajouter \u00e0 la base de donn\u00e9es d'entrainement : Entrez le label dans la zone de texte en bas de la fen\u00eatre. S\u00e9lectionnez avec le clic gauche de la souris des rectangles sur l'image correspondant \u00e0 ce label. Voici par exemple avec notre image Sentinel-2, la s\u00e9lection des labels \"forest\", \"field\", \"water\" et \"city\" : L'id\u00e9e n'est pas de s\u00e9lectionner tous les pixels de l'image correspondant \u00e0 un label donn\u00e9, mais d'\u00eatre le plus repr\u00e9sentatif possible de ce label. Quand vous avez termin\u00e9, cliquez sur \"Finish\". Un message s'affiche dans la console Python : Il contient le nombre de pixels s\u00e9lectionn\u00e9s pour chaque label. La variable df_training contient les donn\u00e9es d'entrainement sous la forme d'un DataFrame Pandas . Il s'agit d'une sorte de tableau, contenant une colonne pour chaque bande de fr\u00e9quence, et une colonne pour le label. Chaque ligne correspond \u00e0 un pixel s\u00e9lectionn\u00e9. Nous utiliserons ce DataFrame pour entrainer notre mod\u00e8le. Nota Bene Il est possible de sauvegarder votre base de donn\u00e9es d'entrainement sous la forme d'un fichier CSV avec la m\u00e9thode Pandas to_csv . Ce CSV pourra \u00eatre import\u00e9 plus tard sous la forme d'un DataFrame Pandas avec la m\u00e9thode read_csv . Vous pouvez \u00e9galement cr\u00e9er des DataFrame Pandas de donn\u00e9es d'entrainement pour diff\u00e9rentes images, et les fusionner en une seule base par la suite, avec la m\u00e9thode concat . Ne n\u00e9gligez surtout pas l'\u00e9tape de la constitution d'une base de donn\u00e9es d'entrainement : un classifieur entrain\u00e9 sur des donn\u00e9es de mauvaise qualit\u00e9 aura des performances mauvaises, Garbage In, Garbage Out . Pour qu'un mod\u00e8le soit performant, il lui faut des donn\u00e9es de qualit\u00e9 (correctement lab\u00e9lis\u00e9es, repr\u00e9sentatives) et en quantit\u00e9 (plusieurs milliers de pixels si possible). Dans l'id\u00e9al, il faut que les donn\u00e9es d'entrainement soient le plus repr\u00e9sentatives possibles des cas d'application de vos projets, en provenant potentiellement de plusieurs images diff\u00e9rentes.","title":"G\u00e9n\u00e9rer une base de donn\u00e9es d'entrainement"},{"location":"entrainement/#etude-statistique-des-donnees","text":"Avant d'entrainer un classifieur, il est important de v\u00e9rifier la s\u00e9parabilit\u00e9 des diff\u00e9rents labels suivants les valeurs dans les diff\u00e9rentes bandes du \"raster\". Et avant d'entrainer un classifieur de type \"d\u00e9cision Bay\u00e9sienne\", il est important de v\u00e9rifier si l' hypoth\u00e8se Gaussienne des distributions a du sens. C'est pourquoi on veut en g\u00e9n\u00e9ral afficher des histogrammes de la r\u00e9partition des valeurs des pixels de notre base d'entrainement pour les diff\u00e9rents labels et pour les diff\u00e9rentes bandes. Ceci est possible avec PyRaTe , en utilisant la commande : PyRaTe.dataset_statistics(df_training) On obtient alors les 10 histogrammes suivants (un par bande) : Certaines bandes du \"raster\" ont-elles l'air plus pertinentes que d'autres pour s\u00e9parer nos diff\u00e9rents labels ? L'hypoth\u00e8se Gaussienne des distributions a-t-elle l'air raisonnable ? Dans le cadre de vos projets, il faudra vous poser ces questions. Nota Bene Si elle n'apporte pas grand chose, une bande peut \u00eatre retir\u00e9e du DataFrame avec la m\u00e9thode Pandas drop . Il faut n\u00e9anmoins avoir en t\u00eate qu'une seule bande est rarement suffisante pour s\u00e9parer 2 labels : il faut souvent utiliser la combinaison de plusieurs bandes.","title":"Etude statistique des donn\u00e9es"},{"location":"entrainement/#entrainement","text":"Maintenant que nous avons v\u00e9rifi\u00e9 la qualit\u00e9 de notre base de donn\u00e9es d'entrainement, nous allons pouvoir l'utiliser pour entrainer notre mod\u00e8le. Voici la commande pour obtenir la \"pipeline\" de notre mod\u00e8le \u00e0 partir des donn\u00e9es d'entrainement (l'apprentissage peut prendre un peu de temps) : classifier_pipeline = PyRaTe.training(df_training) On parle ici de \"pipeline\" car il n'y a en r\u00e9alit\u00e9 pas que le classifieur. Les valeurs de pixels pour les diff\u00e9rentes bandes subissent une mise \u00e0 l'\u00e9chelle avant passage dans le classifieur. Un message apparait dans la console Python : Il s'agit de l' exactitude (\"accuracy\" en anglais) de notre mod\u00e8le sur les donn\u00e9es d'entrainement. Exactitude L'exactitude est un crit\u00e8re de performance classique pour un classifieur. Elle correspond au ratio entre le nombre pr\u00e9dictions correctes et le nombre total de pr\u00e9dictions. Ce crit\u00e8re r\u00e9sume bien les performances d'un classifieur tant que les labels ne sont pas trop d\u00e9s\u00e9quilibr\u00e9s au sein de la base de donn\u00e9es. Ce crit\u00e8re donne par d\u00e9finition des valeurs entre 0 et 1. Plus il est proche de 1, meilleur est le classifieur sur ces donn\u00e9es. L'entrainement s'est-il bien pass\u00e9 ici ? Pensez-vous qu'une exactitude \u00e9lev\u00e9e sur les donn\u00e9es d'entrainement est suffisante pour juger des performances du classifieur de mani\u00e8re g\u00e9n\u00e9rale ?","title":"Entrainement"},{"location":"importation/","text":"Importation d'une image raster Pour commencer, nous allons utiliser PyRaTe pour importer une image satellite multi-bande \u00e0 partir de fichiers GeoTIFF, puis r\u00e9aliser un affichage g\u00e9or\u00e9f\u00e9renc\u00e9 \u00e0 partir de ces donn\u00e9es. Raster et t\u00e9l\u00e9d\u00e9tection Le \"Ra\" de PyRaTe est pour \" Raster \", et le \"Te\" est pour \" T\u00e9l\u00e9d\u00e9tection \". Si vous \u00eates maintenant familiers avec la notion de \"t\u00e9l\u00e9d\u00e9tection\", il est probable que vous n'ayez jamais entendu parler de \"raster\". Il existe 2 grands types d'images : les images matricielles ou \"raster\", et les images vectorielles . Comme leurs noms l'indiquent, l'une est d\u00e9finie par une ou plusieurs matrices 2D, l'autre par des vecteurs. Raster Image constitu\u00e9e d'une (ou plusieurs) matrice 2D. Chaque \u00e9l\u00e9ment dans la matrice correspond \u00e0 un pixel \u00e0 afficher. Les valeurs stock\u00e9es \u00e0 une position dans les matrices 2D correspondent \u00e0 l'intensit\u00e9 des pixels dans diff\u00e9rentes couleurs. Lors de vos projets de t\u00e9l\u00e9d\u00e9tection, vous manipulerez exclusivement des images \"raster\". Importation de fichiers GeoTIFF Vous trouverez dans le dossier \"examples/dataset\" de PyRaTe un jeu de 10 fichiers GeoTIFF. GeoTIFF Le TIFF est un format d'image \"raster\" propri\u00e9taire, mais assez flexible, couramment utilis\u00e9 en t\u00e9l\u00e9d\u00e9tection. En effet, il permet d'enregistrer des m\u00e9tadonn\u00e9es avec l'image, notamment les informations de g\u00e9or\u00e9f\u00e9rencement. Dans ce cas, on appelle le fichier un \"GeoTIFF\". Il s'agit d'une seule image satellite \"raster\" de Saint-Quentin-en-Yvelines, acquise dans 10 bandes diff\u00e9rentes le 19/09/2025 par Sentinel-2. Voici \u00e0 quoi correspondent ces bandes d'acquisition de Sentinel-2 : Bande Cible Longueur d'onde R\u00e9solution au sol B01 A\u00e9rosols 443 nm 60 m B02 Bleu 490 nm 10 m B03 Vert 560 nm 10 m B04 Rouge 665 nm 10 m B05 Red-edge 705 nm 20 m B06 Red-edge 740 nm 20 m B07 Red-edge 783 nm 20 m B08 Proche infrarouge 842 nm 10 m B08A Proche infrarouge \u00e9troit 865 nm 20 m B09 Vapeur d'eau 945 nm 60 m Pour importer ces diff\u00e9rents fichiers GeoTIFF avec PyRaTe , utilisez la commande suivante : band_list,band_bounds = PyRaTe.importation() Apparait alors la fen\u00eatre suivante : Cherchez les fichiers GeoTIFF dans vos dossiers, s\u00e9lectionnez-les et cliquez sur \"Ouvrir\". La variable band_list contiendra alors une liste de matrices Numpy, chacune correspondant \u00e0 une bande. La variable band_bounds contient les limites g\u00e9ographiques de l'image. Si les limites g\u00e9ographiques des diff\u00e9rents \"raster\" import\u00e9s ne sont pas les m\u00eames, un message d'erreur apparaitra. Nota Bene Ici, chaque bande \u00e9tait enregistr\u00e9e dans un GeoTIFF diff\u00e9rent. La fonction g\u00e8re aussi les GeoTIFF contenant plusieurs bandes \u00e0 la fois. Affichages RGB Pour v\u00e9rifier le contenu de nos GeoTIFF, on peut vouloir afficher une image en couleurs (RGB), g\u00e9or\u00e9f\u00e9renc\u00e9e, \u00e0 partir des diff\u00e9rentes bandes import\u00e9es. Le plus classique est de faire un affichage en \" vraies couleurs \" : la bande du \"rouge\" (B04) en rouge, la bande du \"vert\" (B03) en vert, et la bande du \"bleu\" (B02) en bleu. Pour r\u00e9aliser un tel affichage, utilisez la commande suivante : PyRaTe.img_display(band_list,band_bounds,display_rgb=[3,2,1]) Le param\u00e8tre display_rgb vous permet de s\u00e9lectionner dans band_list l'indice des matrices \u00e0 utiliser pour le rouge, le vert et le bleu. On s\u00e9lectionne ici B04, B03 et B02 avec les indices 3, 2 et 1. Voici la figure qui s'affiche : Bien que les longueurs d'ondes per\u00e7ues par le satellite dans ces 3 bandes ne correspondent pas exactement aux pics de sensibilit\u00e9 des \"c\u00f4nes\" de la r\u00e9tine humaine, cet affichage donne un ressenti \"naturel\" des couleurs. En imagerie satellite, il est \u00e9galement classique de r\u00e9aliser un affichage en \" fausses couleurs \" de la mani\u00e8re suivante : la bande du \"proche infrarouge\" (B08) en rouge, la bande du \"rouge\" (B04) en vert, et la bande du \"vert\" (B03) en bleu. Pour r\u00e9aliser un tel affichage, il suffit de reprendre la commande pr\u00e9c\u00e9dente, en modifiant le param\u00e8tre display_rgb : PyRaTe.img_display(band_list,band_bounds,display_rgb=[7,3,2]) Voici la figure qui s'affiche : Ce type d'affichage en \"fausses couleurs\" est particuli\u00e8rement utile pour l'\u00e9tude de la v\u00e9g\u00e9tation : la chloropylle r\u00e9fl\u00e9chit fortement le proche infrarouge, ce qui permet de la faire ressortir en rouge dans l'image. Les contrastes entre zones urbaines, plans d'eaux et v\u00e9g\u00e9tation sont \u00e9galement renforc\u00e9s. Est-ce bien ce que vous observez ? Suivant l'application, on peut imaginer r\u00e9aliser des affichages en \"fausses couleurs\" avec d'autres bandes d'int\u00e9r\u00eat.","title":"Importation"},{"location":"importation/#importation-dune-image-raster","text":"Pour commencer, nous allons utiliser PyRaTe pour importer une image satellite multi-bande \u00e0 partir de fichiers GeoTIFF, puis r\u00e9aliser un affichage g\u00e9or\u00e9f\u00e9renc\u00e9 \u00e0 partir de ces donn\u00e9es.","title":"Importation d'une image raster"},{"location":"importation/#raster-et-teledetection","text":"Le \"Ra\" de PyRaTe est pour \" Raster \", et le \"Te\" est pour \" T\u00e9l\u00e9d\u00e9tection \". Si vous \u00eates maintenant familiers avec la notion de \"t\u00e9l\u00e9d\u00e9tection\", il est probable que vous n'ayez jamais entendu parler de \"raster\". Il existe 2 grands types d'images : les images matricielles ou \"raster\", et les images vectorielles . Comme leurs noms l'indiquent, l'une est d\u00e9finie par une ou plusieurs matrices 2D, l'autre par des vecteurs. Raster Image constitu\u00e9e d'une (ou plusieurs) matrice 2D. Chaque \u00e9l\u00e9ment dans la matrice correspond \u00e0 un pixel \u00e0 afficher. Les valeurs stock\u00e9es \u00e0 une position dans les matrices 2D correspondent \u00e0 l'intensit\u00e9 des pixels dans diff\u00e9rentes couleurs. Lors de vos projets de t\u00e9l\u00e9d\u00e9tection, vous manipulerez exclusivement des images \"raster\".","title":"Raster et t\u00e9l\u00e9d\u00e9tection"},{"location":"importation/#importation-de-fichiers-geotiff","text":"Vous trouverez dans le dossier \"examples/dataset\" de PyRaTe un jeu de 10 fichiers GeoTIFF. GeoTIFF Le TIFF est un format d'image \"raster\" propri\u00e9taire, mais assez flexible, couramment utilis\u00e9 en t\u00e9l\u00e9d\u00e9tection. En effet, il permet d'enregistrer des m\u00e9tadonn\u00e9es avec l'image, notamment les informations de g\u00e9or\u00e9f\u00e9rencement. Dans ce cas, on appelle le fichier un \"GeoTIFF\". Il s'agit d'une seule image satellite \"raster\" de Saint-Quentin-en-Yvelines, acquise dans 10 bandes diff\u00e9rentes le 19/09/2025 par Sentinel-2. Voici \u00e0 quoi correspondent ces bandes d'acquisition de Sentinel-2 : Bande Cible Longueur d'onde R\u00e9solution au sol B01 A\u00e9rosols 443 nm 60 m B02 Bleu 490 nm 10 m B03 Vert 560 nm 10 m B04 Rouge 665 nm 10 m B05 Red-edge 705 nm 20 m B06 Red-edge 740 nm 20 m B07 Red-edge 783 nm 20 m B08 Proche infrarouge 842 nm 10 m B08A Proche infrarouge \u00e9troit 865 nm 20 m B09 Vapeur d'eau 945 nm 60 m Pour importer ces diff\u00e9rents fichiers GeoTIFF avec PyRaTe , utilisez la commande suivante : band_list,band_bounds = PyRaTe.importation() Apparait alors la fen\u00eatre suivante : Cherchez les fichiers GeoTIFF dans vos dossiers, s\u00e9lectionnez-les et cliquez sur \"Ouvrir\". La variable band_list contiendra alors une liste de matrices Numpy, chacune correspondant \u00e0 une bande. La variable band_bounds contient les limites g\u00e9ographiques de l'image. Si les limites g\u00e9ographiques des diff\u00e9rents \"raster\" import\u00e9s ne sont pas les m\u00eames, un message d'erreur apparaitra. Nota Bene Ici, chaque bande \u00e9tait enregistr\u00e9e dans un GeoTIFF diff\u00e9rent. La fonction g\u00e8re aussi les GeoTIFF contenant plusieurs bandes \u00e0 la fois.","title":"Importation de fichiers GeoTIFF"},{"location":"importation/#affichages-rgb","text":"Pour v\u00e9rifier le contenu de nos GeoTIFF, on peut vouloir afficher une image en couleurs (RGB), g\u00e9or\u00e9f\u00e9renc\u00e9e, \u00e0 partir des diff\u00e9rentes bandes import\u00e9es. Le plus classique est de faire un affichage en \" vraies couleurs \" : la bande du \"rouge\" (B04) en rouge, la bande du \"vert\" (B03) en vert, et la bande du \"bleu\" (B02) en bleu. Pour r\u00e9aliser un tel affichage, utilisez la commande suivante : PyRaTe.img_display(band_list,band_bounds,display_rgb=[3,2,1]) Le param\u00e8tre display_rgb vous permet de s\u00e9lectionner dans band_list l'indice des matrices \u00e0 utiliser pour le rouge, le vert et le bleu. On s\u00e9lectionne ici B04, B03 et B02 avec les indices 3, 2 et 1. Voici la figure qui s'affiche : Bien que les longueurs d'ondes per\u00e7ues par le satellite dans ces 3 bandes ne correspondent pas exactement aux pics de sensibilit\u00e9 des \"c\u00f4nes\" de la r\u00e9tine humaine, cet affichage donne un ressenti \"naturel\" des couleurs. En imagerie satellite, il est \u00e9galement classique de r\u00e9aliser un affichage en \" fausses couleurs \" de la mani\u00e8re suivante : la bande du \"proche infrarouge\" (B08) en rouge, la bande du \"rouge\" (B04) en vert, et la bande du \"vert\" (B03) en bleu. Pour r\u00e9aliser un tel affichage, il suffit de reprendre la commande pr\u00e9c\u00e9dente, en modifiant le param\u00e8tre display_rgb : PyRaTe.img_display(band_list,band_bounds,display_rgb=[7,3,2]) Voici la figure qui s'affiche : Ce type d'affichage en \"fausses couleurs\" est particuli\u00e8rement utile pour l'\u00e9tude de la v\u00e9g\u00e9tation : la chloropylle r\u00e9fl\u00e9chit fortement le proche infrarouge, ce qui permet de la faire ressortir en rouge dans l'image. Les contrastes entre zones urbaines, plans d'eaux et v\u00e9g\u00e9tation sont \u00e9galement renforc\u00e9s. Est-ce bien ce que vous observez ? Suivant l'application, on peut imaginer r\u00e9aliser des affichages en \"fausses couleurs\" avec d'autres bandes d'int\u00e9r\u00eat.","title":"Affichages RGB"},{"location":"prediction/","text":"Pr\u00e9diction de labels Maintenant que nous avons valid\u00e9 les performances de notre classifieur en g\u00e9n\u00e9ralisation, nous pouvons l'utiliser avec confiance pour pr\u00e9dire les labels de tous les pixels de notre image \"raster\". PyRaTe permet \u00e0 la fois la pr\u00e9diction et l'affichage des labels pr\u00e9dits. Pr\u00e9dire avec un classifieur Avec PyRaTe , pour pr\u00e9dire les labels des pixels avec le classifieur que vous avez entrain\u00e9, utilisez la commande suivante : img_label,labels_code = PyRaTe.prediction(classifier_pipeline,band_list) Il y a 2 variables de sortie : img_label est une matrice Numpy contenant des nombres entiers, correspondant aux diff\u00e9rents labels. labels_code est une matrice Numpy contenant les diff\u00e9rents labels dans l'ordre des nombres entiers de img_label . Ces 2 sorties, associ\u00e9es aux donn\u00e9es de g\u00e9or\u00e9f\u00e9rencement du \"raster\" permettent d'afficher les pr\u00e9dictions pour notre image. Vous pouvez \u00e9galement appliquer cette fonction \u00e0 de nouvelles images \u00e0 classifier. Affichage des labels Avec PyRaTe , pour afficher les labels pr\u00e9dits pour une image, avec le g\u00e9or\u00e9f\u00e9rencement, utilisez la commande suivante : PyRaTe.label_display(img_label,band_bounds,labels_code) Voici la figure qui s'affiche alors : Les diff\u00e9rentes couleurs permettent d'identifier les 4 labels (\"forest\", \"field\", \"water\" et \"city\"). Nous avons obtenu le r\u00e9sultat attendu ! Nota Bene Si dans le cadre de vos projets de t\u00e9l\u00e9d\u00e9tection, vous voulez d\u00e9terminer le nombre de pixels assign\u00e9s \u00e0 un label pour un calcul de surface, c'est possible. Il suffit avec Numpy de calculer le nombre d'\u00e9l\u00e9ments dans la matrice img_label \u00e9gaux \u00e0 l'entier correspondant au label \u00e0 d\u00e9nombrer. Pour aller plus loin ... Lors de vos projets, vous devrez choisir vous m\u00eame les images satellites dont vous aurez besoin. Pour faire ce choix, vous devrez vous poser les questions suivantes : Quel satellite ou constellation de satellites choisir ? (Les capteurs qu'il contient, les temps de revisite, la disponibilit\u00e9 des donn\u00e9es pour les dates cherch\u00e9es, etc.). Quelles bandes de fr\u00e9quences choisir ? (Les bandes pertinentes pour d\u00e9tecter les surfaces que vous voulez \u00e9tudier, avec la r\u00e9solution dont vous avez besoin, etc.). Quelles r\u00e9gions et quelles dates choisir ? (La m\u00eame saison ou des saisons diff\u00e9rentes, la m\u00eame r\u00e9gion ou des r\u00e9gions diff\u00e9rentes, etc.). Pour trouver des images satellites \"raster\" de satellites Sentinel au format GeoTIFF, pour une s\u00e9lection de bandes de fr\u00e9quences, vous pouvez utiliser le moteur de recherche de Copernicus : Le browser de Copernicus Pour t\u00e9l\u00e9charger les GeoTIFF bruts des diff\u00e9rentes bandes, vous devrez d'abord cr\u00e9er un compte. Ensuite, il faut cliquer sur le bouton \"Download image\", et dans la fen\u00eatre qui s'ouvre cliquer sur \"Analytical\". Vous pouvez alors s\u00e9lectionner le format, la r\u00e9solution et les bandes de l'image \u00e0 t\u00e9l\u00e9charger. Par d\u00e9faut, nous vous recommandons de t\u00e9l\u00e9charger : TIFF encod\u00e9 sur 16 bits. R\u00e9solution \"HIGH\". Syst\u00e8me de coordonn\u00e9es WGS84. Les bandes dont vous avez besoin dans la cat\u00e9gorie \"Raw\". Vous pouvez bien entendu choisir des images satellites de type \"raster\" provenant de n'importe quel satellite et les utiliser avec PyRaTe .","title":"Prediction"},{"location":"prediction/#prediction-de-labels","text":"Maintenant que nous avons valid\u00e9 les performances de notre classifieur en g\u00e9n\u00e9ralisation, nous pouvons l'utiliser avec confiance pour pr\u00e9dire les labels de tous les pixels de notre image \"raster\". PyRaTe permet \u00e0 la fois la pr\u00e9diction et l'affichage des labels pr\u00e9dits.","title":"Pr\u00e9diction de labels"},{"location":"prediction/#predire-avec-un-classifieur","text":"Avec PyRaTe , pour pr\u00e9dire les labels des pixels avec le classifieur que vous avez entrain\u00e9, utilisez la commande suivante : img_label,labels_code = PyRaTe.prediction(classifier_pipeline,band_list) Il y a 2 variables de sortie : img_label est une matrice Numpy contenant des nombres entiers, correspondant aux diff\u00e9rents labels. labels_code est une matrice Numpy contenant les diff\u00e9rents labels dans l'ordre des nombres entiers de img_label . Ces 2 sorties, associ\u00e9es aux donn\u00e9es de g\u00e9or\u00e9f\u00e9rencement du \"raster\" permettent d'afficher les pr\u00e9dictions pour notre image. Vous pouvez \u00e9galement appliquer cette fonction \u00e0 de nouvelles images \u00e0 classifier.","title":"Pr\u00e9dire avec un classifieur"},{"location":"prediction/#affichage-des-labels","text":"Avec PyRaTe , pour afficher les labels pr\u00e9dits pour une image, avec le g\u00e9or\u00e9f\u00e9rencement, utilisez la commande suivante : PyRaTe.label_display(img_label,band_bounds,labels_code) Voici la figure qui s'affiche alors : Les diff\u00e9rentes couleurs permettent d'identifier les 4 labels (\"forest\", \"field\", \"water\" et \"city\"). Nous avons obtenu le r\u00e9sultat attendu ! Nota Bene Si dans le cadre de vos projets de t\u00e9l\u00e9d\u00e9tection, vous voulez d\u00e9terminer le nombre de pixels assign\u00e9s \u00e0 un label pour un calcul de surface, c'est possible. Il suffit avec Numpy de calculer le nombre d'\u00e9l\u00e9ments dans la matrice img_label \u00e9gaux \u00e0 l'entier correspondant au label \u00e0 d\u00e9nombrer.","title":"Affichage des labels"},{"location":"prediction/#pour-aller-plus-loin","text":"Lors de vos projets, vous devrez choisir vous m\u00eame les images satellites dont vous aurez besoin. Pour faire ce choix, vous devrez vous poser les questions suivantes : Quel satellite ou constellation de satellites choisir ? (Les capteurs qu'il contient, les temps de revisite, la disponibilit\u00e9 des donn\u00e9es pour les dates cherch\u00e9es, etc.). Quelles bandes de fr\u00e9quences choisir ? (Les bandes pertinentes pour d\u00e9tecter les surfaces que vous voulez \u00e9tudier, avec la r\u00e9solution dont vous avez besoin, etc.). Quelles r\u00e9gions et quelles dates choisir ? (La m\u00eame saison ou des saisons diff\u00e9rentes, la m\u00eame r\u00e9gion ou des r\u00e9gions diff\u00e9rentes, etc.). Pour trouver des images satellites \"raster\" de satellites Sentinel au format GeoTIFF, pour une s\u00e9lection de bandes de fr\u00e9quences, vous pouvez utiliser le moteur de recherche de Copernicus : Le browser de Copernicus Pour t\u00e9l\u00e9charger les GeoTIFF bruts des diff\u00e9rentes bandes, vous devrez d'abord cr\u00e9er un compte. Ensuite, il faut cliquer sur le bouton \"Download image\", et dans la fen\u00eatre qui s'ouvre cliquer sur \"Analytical\". Vous pouvez alors s\u00e9lectionner le format, la r\u00e9solution et les bandes de l'image \u00e0 t\u00e9l\u00e9charger. Par d\u00e9faut, nous vous recommandons de t\u00e9l\u00e9charger : TIFF encod\u00e9 sur 16 bits. R\u00e9solution \"HIGH\". Syst\u00e8me de coordonn\u00e9es WGS84. Les bandes dont vous avez besoin dans la cat\u00e9gorie \"Raw\". Vous pouvez bien entendu choisir des images satellites de type \"raster\" provenant de n'importe quel satellite et les utiliser avec PyRaTe .","title":"Pour aller plus loin ..."},{"location":"test/","text":"Test d'un classifieur Nous avons un classifieur pr\u00eat \u00e0 \u00eatre utilis\u00e9. Mais avant de l'appliquer \u00e0 nos donn\u00e9es d'\u00e9tude, nous aimerions \u00eatre s\u00fbrs qu'il performera bien sur des donn\u00e9es qu'il n'a jamais vues. Nous allons donc le tester avec PyRaTe . Probl\u00e8me du sur-apprentissage En apprentissage automatique, le nerf de la guerre est la g\u00e9n\u00e9ralisation . En effet, un mod\u00e8le qui a d'excellente performances sur les donn\u00e9es d'entrainement, mais de mauvaises performances sur n'importe quelles autres donn\u00e9es ne sert \u00e0 rien . On veut que le mod\u00e8le soit capable de g\u00e9n\u00e9raliser ce qu'il a apprit. Ceci peut arriver lorsqu'un mod\u00e8le apprend trop sp\u00e9cifiquement des donn\u00e9es d'entrainement. C'est ce que l'on appelle le sur-apprentissage , et c'est la hantise de tous les \"data-scientists\". Voici une illustration sur un probl\u00e8me de r\u00e9gression : Le mod\u00e8le de gauche est visiblement trop simpliste pour capturer la tendance principale des donn\u00e9es : on parle de sous-apprentissage . Le mod\u00e8le de droite est visiblement trop complexe, et capture m\u00eame le bruit dans les donn\u00e9es d'entrainement. Il aura donc d'excellentes performances sur les donn\u00e9es d'entrainement, mais aura du mal \u00e0 g\u00e9n\u00e9raliser : il y a sur-apprentissage . Le mod\u00e8le id\u00e9al est au milieu : assez complexe pour capturer la tendance principale des donn\u00e9es d'entrainement, sans aller jusqu'\u00e0 apprendre le bruit dans les donn\u00e9es. Le sur-apprentissage peut avoir diff\u00e9rentes origines : Trop peu de donn\u00e9es d'entrainement. Des donn\u00e9es d'entrainement pas assez repr\u00e9sentatives. Des donn\u00e9es de mauvaise qualit\u00e9 (mauvais labels, d\u00e9s\u00e9quilibre entre labels, etc.). Un type de mod\u00e8le trop complexe. Trop peu de d'entr\u00e9es au mod\u00e8le. Dans le contexte de vos projet, en cas de de sur-apprentissage, vous pouvez essayer : D'ajouter des pixels \u00e0 vos donn\u00e9es d'entrainement. De re-faire votre base de donn\u00e9es d'entrainement avec des zones plus repr\u00e9sentatives. Ajouter des bandes pertinentes \u00e0 vos donn\u00e9es d'entrainement. Pour plus d'informations sur le sur-apprentissage, cliquez sur ce lien : Cours sur le sur-apprentissage . Mais reste alors une question : comment d\u00e9tecter un sur-apprentissage ? G\u00e9n\u00e9rer une base de donn\u00e9es de test Le sur-apprentissage est par d\u00e9finition la sous-performance d'un mod\u00e8le en g\u00e9n\u00e9ralisation. La m\u00e9thode classique que nous appliquerons pour d\u00e9tecter ce ph\u00e9nom\u00e8ne sera donc tout simplement de tester notre classifieur sur une base de donn\u00e9es de pixels autres que ceux de l'entrainement . Si le classifieur performe significativement moins bien en test qu'\u00e0 l'entrainement, c'est qu'il y a probablement sur-apprentissage . Il nous faut donc constituer une base de donn\u00e9es de test . Pour vos projets de t\u00e9l\u00e9d\u00e9tection, il faudra que vos tests soient les plus repr\u00e9sentatifs possibles des cas sur lesquels vous voulez appliquer votre classifieur : Si vous voulez un classifieur capable de g\u00e9n\u00e9raliser \u00e0 diff\u00e9rentes r\u00e9gions du monde, il faudra tester diff\u00e9rentes r\u00e9gions. Si vous voulez un classifieur capable de g\u00e9n\u00e9raliser \u00e0 diff\u00e9rentes saisons pour une m\u00eame r\u00e9gion, il faudra tester diff\u00e9rentes saisons. Si vous pouvez vous contenter d'un classifieur capable de g\u00e9n\u00e9raliser \u00e0 une r\u00e9gion et une temporalit\u00e9, vous pouvez tester sur des pixels issus de la m\u00eame image. Pour notre exemple, nous allons s\u00e9lectionner des pixels issus de la m\u00eame image, mais pour des zones de l'image sur lesquelles le classifieur n'a pas \u00e9t\u00e9 entrain\u00e9. Nous utilisons \u00e0 nouveau PyRaTe avec la commande suivante : df_test = PyRaTe.labelling(band_list,display_rgb=[3,2,1]) La fen\u00eatre de lab\u00e9lisation s'ouvre, et nous pouvons s\u00e9lectionner des pixels \u00e0 ajouter \u00e0 notre base de donn\u00e9es de test pour les m\u00eames labels (\"forest\", \"field\", \"water\", \"city\") : Apr\u00e8s avoir cliqu\u00e9 sur \"Finish\", nous obtenons le message suivant dans la console Python : Il contient le nombre de pixels s\u00e9lectionn\u00e9s pour chaque label. La variable df_test contient alors notre base de donn\u00e9es de test, sous le m\u00eame format que notre base de donn\u00e9es d'entrainement. Nota Bene Vous pouvez cr\u00e9er plusieurs bases de donn\u00e9es de tests sur plusieurs images diff\u00e9rentes pour r\u00e9aliser diff\u00e9rents tests. Performances en g\u00e9n\u00e9ralisation Une fois la base de donn\u00e9es de test constitu\u00e9e, nous pouvons utiliser PyRaTe pour le test proprement dit. Pour r\u00e9aliser un test de notre \"pipeline\" sur notre jeu de donn\u00e9es d'entrainement, utilisez la commande : PyRaTe.test(classifier_pipeline,df_test) Apparait alors le message suivant dans la console Python, avec le score d'exactitude du classifieur en test : D\u00e9tectez-vous ici un probl\u00e8me de sur-apprentissage ? Nota Bene N'oubliez pas que le score de d'exactitude est inadapt\u00e9 quand on a un fort d\u00e9s\u00e9quilibre dans les labels de notre base de donn\u00e9es. La fen\u00eatre suivante apparait aussi : Ce type de tableau se nomme une matrice de confusion . Il permet de rapidement identifier l'origine des erreurs de pr\u00e9diction de notre classifieur sur les donn\u00e9es de test. D'un point de vue g\u00e9n\u00e9ral : La diagonale correspond au nombre de pixels dont le label a \u00e9t\u00e9 correctement pr\u00e9dit. Hors de la diagonale sont les nombres de pixels pour lesquels les labels n'ont pas \u00e9t\u00e9 correctement pr\u00e9dit. Du point de vue d'un label en particulier, il y a 4 types d'erreurs : TP : les vrais positifs, ce label a \u00e9t\u00e9 pr\u00e9dit et c'\u00e9tait le bon label. TN : le vrais n\u00e9gatifs, ce label n'a pas \u00e9t\u00e9 pr\u00e9dit et ce n'\u00e9tait pas le bon label. FP : les faux positifs, ce label a \u00e9t\u00e9 pr\u00e9dit mais ce n'\u00e9tait pas le bon label. FN : les faux n\u00e9gatifs, ce label n'a pas \u00e9t\u00e9 pr\u00e9dit mais c'\u00e9tait le bon label. Voici une illustration des 2 points de vues : Dans notre cas, d'o\u00f9 viennent principalement les erreurs de pr\u00e9diction en test ? Quelles performances / erreurs peuvent \u00eatre attendues en g\u00e9n\u00e9ralisation sur l'image compl\u00e8te ? Avons-nous la garantie que le classifieur performerait bien sur une image d'une autre r\u00e9gion ou \u00e0 une autre saison ?","title":"Test"},{"location":"test/#test-dun-classifieur","text":"Nous avons un classifieur pr\u00eat \u00e0 \u00eatre utilis\u00e9. Mais avant de l'appliquer \u00e0 nos donn\u00e9es d'\u00e9tude, nous aimerions \u00eatre s\u00fbrs qu'il performera bien sur des donn\u00e9es qu'il n'a jamais vues. Nous allons donc le tester avec PyRaTe .","title":"Test d'un classifieur"},{"location":"test/#probleme-du-sur-apprentissage","text":"En apprentissage automatique, le nerf de la guerre est la g\u00e9n\u00e9ralisation . En effet, un mod\u00e8le qui a d'excellente performances sur les donn\u00e9es d'entrainement, mais de mauvaises performances sur n'importe quelles autres donn\u00e9es ne sert \u00e0 rien . On veut que le mod\u00e8le soit capable de g\u00e9n\u00e9raliser ce qu'il a apprit. Ceci peut arriver lorsqu'un mod\u00e8le apprend trop sp\u00e9cifiquement des donn\u00e9es d'entrainement. C'est ce que l'on appelle le sur-apprentissage , et c'est la hantise de tous les \"data-scientists\". Voici une illustration sur un probl\u00e8me de r\u00e9gression : Le mod\u00e8le de gauche est visiblement trop simpliste pour capturer la tendance principale des donn\u00e9es : on parle de sous-apprentissage . Le mod\u00e8le de droite est visiblement trop complexe, et capture m\u00eame le bruit dans les donn\u00e9es d'entrainement. Il aura donc d'excellentes performances sur les donn\u00e9es d'entrainement, mais aura du mal \u00e0 g\u00e9n\u00e9raliser : il y a sur-apprentissage . Le mod\u00e8le id\u00e9al est au milieu : assez complexe pour capturer la tendance principale des donn\u00e9es d'entrainement, sans aller jusqu'\u00e0 apprendre le bruit dans les donn\u00e9es. Le sur-apprentissage peut avoir diff\u00e9rentes origines : Trop peu de donn\u00e9es d'entrainement. Des donn\u00e9es d'entrainement pas assez repr\u00e9sentatives. Des donn\u00e9es de mauvaise qualit\u00e9 (mauvais labels, d\u00e9s\u00e9quilibre entre labels, etc.). Un type de mod\u00e8le trop complexe. Trop peu de d'entr\u00e9es au mod\u00e8le. Dans le contexte de vos projet, en cas de de sur-apprentissage, vous pouvez essayer : D'ajouter des pixels \u00e0 vos donn\u00e9es d'entrainement. De re-faire votre base de donn\u00e9es d'entrainement avec des zones plus repr\u00e9sentatives. Ajouter des bandes pertinentes \u00e0 vos donn\u00e9es d'entrainement. Pour plus d'informations sur le sur-apprentissage, cliquez sur ce lien : Cours sur le sur-apprentissage . Mais reste alors une question : comment d\u00e9tecter un sur-apprentissage ?","title":"Probl\u00e8me du sur-apprentissage"},{"location":"test/#generer-une-base-de-donnees-de-test","text":"Le sur-apprentissage est par d\u00e9finition la sous-performance d'un mod\u00e8le en g\u00e9n\u00e9ralisation. La m\u00e9thode classique que nous appliquerons pour d\u00e9tecter ce ph\u00e9nom\u00e8ne sera donc tout simplement de tester notre classifieur sur une base de donn\u00e9es de pixels autres que ceux de l'entrainement . Si le classifieur performe significativement moins bien en test qu'\u00e0 l'entrainement, c'est qu'il y a probablement sur-apprentissage . Il nous faut donc constituer une base de donn\u00e9es de test . Pour vos projets de t\u00e9l\u00e9d\u00e9tection, il faudra que vos tests soient les plus repr\u00e9sentatifs possibles des cas sur lesquels vous voulez appliquer votre classifieur : Si vous voulez un classifieur capable de g\u00e9n\u00e9raliser \u00e0 diff\u00e9rentes r\u00e9gions du monde, il faudra tester diff\u00e9rentes r\u00e9gions. Si vous voulez un classifieur capable de g\u00e9n\u00e9raliser \u00e0 diff\u00e9rentes saisons pour une m\u00eame r\u00e9gion, il faudra tester diff\u00e9rentes saisons. Si vous pouvez vous contenter d'un classifieur capable de g\u00e9n\u00e9raliser \u00e0 une r\u00e9gion et une temporalit\u00e9, vous pouvez tester sur des pixels issus de la m\u00eame image. Pour notre exemple, nous allons s\u00e9lectionner des pixels issus de la m\u00eame image, mais pour des zones de l'image sur lesquelles le classifieur n'a pas \u00e9t\u00e9 entrain\u00e9. Nous utilisons \u00e0 nouveau PyRaTe avec la commande suivante : df_test = PyRaTe.labelling(band_list,display_rgb=[3,2,1]) La fen\u00eatre de lab\u00e9lisation s'ouvre, et nous pouvons s\u00e9lectionner des pixels \u00e0 ajouter \u00e0 notre base de donn\u00e9es de test pour les m\u00eames labels (\"forest\", \"field\", \"water\", \"city\") : Apr\u00e8s avoir cliqu\u00e9 sur \"Finish\", nous obtenons le message suivant dans la console Python : Il contient le nombre de pixels s\u00e9lectionn\u00e9s pour chaque label. La variable df_test contient alors notre base de donn\u00e9es de test, sous le m\u00eame format que notre base de donn\u00e9es d'entrainement. Nota Bene Vous pouvez cr\u00e9er plusieurs bases de donn\u00e9es de tests sur plusieurs images diff\u00e9rentes pour r\u00e9aliser diff\u00e9rents tests.","title":"G\u00e9n\u00e9rer une base de donn\u00e9es de test"},{"location":"test/#performances-en-generalisation","text":"Une fois la base de donn\u00e9es de test constitu\u00e9e, nous pouvons utiliser PyRaTe pour le test proprement dit. Pour r\u00e9aliser un test de notre \"pipeline\" sur notre jeu de donn\u00e9es d'entrainement, utilisez la commande : PyRaTe.test(classifier_pipeline,df_test) Apparait alors le message suivant dans la console Python, avec le score d'exactitude du classifieur en test : D\u00e9tectez-vous ici un probl\u00e8me de sur-apprentissage ? Nota Bene N'oubliez pas que le score de d'exactitude est inadapt\u00e9 quand on a un fort d\u00e9s\u00e9quilibre dans les labels de notre base de donn\u00e9es. La fen\u00eatre suivante apparait aussi : Ce type de tableau se nomme une matrice de confusion . Il permet de rapidement identifier l'origine des erreurs de pr\u00e9diction de notre classifieur sur les donn\u00e9es de test. D'un point de vue g\u00e9n\u00e9ral : La diagonale correspond au nombre de pixels dont le label a \u00e9t\u00e9 correctement pr\u00e9dit. Hors de la diagonale sont les nombres de pixels pour lesquels les labels n'ont pas \u00e9t\u00e9 correctement pr\u00e9dit. Du point de vue d'un label en particulier, il y a 4 types d'erreurs : TP : les vrais positifs, ce label a \u00e9t\u00e9 pr\u00e9dit et c'\u00e9tait le bon label. TN : le vrais n\u00e9gatifs, ce label n'a pas \u00e9t\u00e9 pr\u00e9dit et ce n'\u00e9tait pas le bon label. FP : les faux positifs, ce label a \u00e9t\u00e9 pr\u00e9dit mais ce n'\u00e9tait pas le bon label. FN : les faux n\u00e9gatifs, ce label n'a pas \u00e9t\u00e9 pr\u00e9dit mais c'\u00e9tait le bon label. Voici une illustration des 2 points de vues : Dans notre cas, d'o\u00f9 viennent principalement les erreurs de pr\u00e9diction en test ? Quelles performances / erreurs peuvent \u00eatre attendues en g\u00e9n\u00e9ralisation sur l'image compl\u00e8te ? Avons-nous la garantie que le classifieur performerait bien sur une image d'une autre r\u00e9gion ou \u00e0 une autre saison ?","title":"Performances en g\u00e9n\u00e9ralisation"}]}